Part 1 : Machine Learning
Task 1.1 - Data Preperation
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import random
import csv
import numpy as np
​
# Loading dataset
column_names = ['Ship_ID', 'Name', 'Year built', 'Gross tonnage', 'Deadweight tonnage', 'Length of ship', 'Width of ship', 'Capacity', 'Number of forward bays', 'Number of centre bays', 'Number of aft bays']
data = pd.read_csv('containers.csv', names=column_names, delimiter=',')
Names = data['Name']
# Remove non-numeric columns from data
#data = data[['Name','Year built', 'Gross tonnage', 'Deadweight tonnage', 'Length of ship', 'Width of ship', 'Number of forward bays', 'Number of centre bays', 'Number of aft bays', 'Capacity']]
​
# Extracting the features (inputs) and target variable (output)
features = data[['Year built', 'Gross tonnage', 'Deadweight tonnage', 'Length of ship', 'Width of ship', 'Number of forward bays', 'Number of centre bays', 'Number of aft bays']]
target = data['Capacity']
​
# Performing min-max normalization
scaler = MinMaxScaler()
normalized_features = scaler.fit_transform(features)
​
# Creating a new DataFrame with the normalized features and target variable
normalized_data = pd.DataFrame(normalized_features, columns=features.columns)
normalized_data['Capacity'] = target
normalized_data['Name']=Names
​
# Displaying the normalized data
normalized_data.head()
Year built	Gross tonnage	Deadweight tonnage	Length of ship	Width of ship	Number of forward bays	Number of centre bays	Number of aft bays	Capacity	Name
0	0.538462	0.386100	0.449728	0.825774	0.088234	0.818182	0.0	0.6	8272	ANNA MAERSK
1	0.743590	0.475606	0.508492	0.812541	0.099189	0.818182	0.0	0.5	10106	APL CHONGQING
2	0.615385	0.016677	0.015372	0.023892	0.013235	0.181818	0.0	0.0	868	BF EUPHORIA
3	0.666667	0.387224	0.425541	0.761303	0.088496	0.818182	0.0	0.5	8749	BREMEN EXPRESS
4	0.615385	0.100548	0.138990	0.346284	0.040528	0.454545	0.0	0.2	2824	CAMELLIA
Task 1.2 - Regression
# Extracting the features (inputs) and target variable (output)
features = normalized_data[['Year built', 'Gross tonnage', 'Deadweight tonnage', 'Length of ship', 'Width of ship', 'Number of forward bays', 'Number of centre bays', 'Number of aft bays']]
target = normalized_data['Capacity']
​
# Training the Random Forest regressor
rf_regressor = RandomForestRegressor()
rf_regressor.fit(features, target)
​
# Training the Neural Network regressor
nn_regressor = MLPRegressor()
nn_regressor.fit(features, target)
​
# Training the Support Vector Machine regressor
svm_regressor = SVR()
svm_regressor.fit(features, target)
​
# Creating a new DataFrame for predictions
predictions = pd.DataFrame(normalized_data['Name'], columns=['Name'])
predictions['Random Forest'] = rf_regressor.predict(features)
predictions['Neural Network'] = nn_regressor.predict(features)
predictions['Support Vector Machine'] = svm_regressor.predict(features)
​
# Sorting DataFrame by predicted capacity using the descending order
predictions = predictions.sort_values(by='Random Forest', ascending=False)
​
# Displayiing the top ten container ships with predicted capacity
predictions.head(10)
/home/wakat/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(
Name	Random Forest	Neural Network	Support Vector Machine
96	HMM HELSINKI	23528.61	31.143499	8679.355264
97	HMM STOCKHOLM	23466.69	31.149469	8679.339968
99	COSCO SHIPPING UNIVERSE	21119.93	29.766917	8680.326326
91	OOCL HONG KONG	20863.83	29.675272	8682.801760
95	CMA CGM ANTOINE DE SAINT EXUPERY	20784.65	29.985252	8681.639624
98	MILAN MAERSK	20657.27	29.547466	8681.281834
90	ONE TRIBUTE	20421.92	29.845984	8682.611286
94	MOL TREASURE	20286.35	29.624989	8682.827647
85	COSCO SHIPPING CAPRICORN	19949.56	29.591207	8682.670927
84	AL DAHNA	19752.10	29.391977	8682.664011
Task 1.3 – Assessment of regression
# Extracting the features (inputs) and target variable (output)
features = data[['Year built', 'Gross tonnage', 'Deadweight tonnage', 'Length of ship', 'Width of ship', 'Number of forward bays', 'Number of centre bays', 'Number of aft bays']]
target = data['Capacity']
​
# Performing cross-validation
# Using the regression models from part 1.2
linear_mse_scores = -cross_val_score(nn_regressor, features, target, scoring='neg_mean_squared_error', cv=10)
​
svm_mse_scores = -cross_val_score(svm_regressor, features, target, scoring='neg_mean_squared_error', cv=10)
​
rf_mse_scores = -cross_val_score(rf_regressor, features, target, scoring='neg_mean_squared_error', cv=10)
​
​
# Combining the MSE scores for plotting
all_mse_scores = [linear_mse_scores, rf_mse_scores, svm_mse_scores]
model_labels = ['Neural Network', 'Random Forest', 'Support Vector Machine']
​
# Plotting the MSE scores using a boxplot
plt.boxplot(all_mse_scores, labels=model_labels)
plt.xlabel('Regression Model')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('Regression Models')
plt.show()
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[1], line 2
      1 # Extracting the features (inputs) and target variable (output)
----> 2 features = data[['Year built', 'Gross tonnage', 'Deadweight tonnage', 'Length of ship', 'Width of ship', 'Number of forward bays', 'Number of centre bays', 'Number of aft bays']]
      3 target = data['Capacity']
      5 # Performing cross-validation
      6 # calculating our  MSE value and Support Vector Machine

NameError: name 'data' is not defined

Part 2 – OPTIMISATION
Task 2.1 – Generation of random solutions
def read_distances(filename):
    distances = []
    with open(filename, 'r') as file:
        reader = csv.reader(file)
        for row in reader:
            distances.append(list(map(float, row)))
    return distances
​
# calculating the distance
​
def calculate_distance(route, distances):
    total_distance = 0
    for i in range(len(route) - 1):
        start = route[i] - 1  # Adjusting stop indices to match the distance matrix
        end = route[i + 1] - 1
        total_distance += distances[start][end]
    return total_distance
​
​
# calculating the fitness
def calculate_fitness(route, distances):
    distance = calculate_distance(route, distances)
​
    # Constraints
    violations = 0
    num_stops = len(route)
    num_routes = num_stops // 4
​
    # Checking if each route visits exactly 4 stops
    for i in range(num_routes):
        route_stops = route[i * 4: (i + 1) * 4]
        if len(set(route_stops)) < 4:
            violations += 1
​
    # Checking if all stops are visited
    if len(set(route)) != num_stops:
        violations += 1
​
    # calculation
    fitness = distance + violations * 1000  # Penalty for constraint violations
    return fitness
​
​
stops = list(range(1, 13))
distances = read_distances('distances.csv')
​
# Generating a random route
random_route = random.sample(stops, len(stops))
​
# Calculate fitness
fitness = calculate_fitness(random_route, distances)
print("Fitness:", fitness)
Fitness: 87.25664797664825
Task 2.2 – Algorithm implementation
def shuffle_mutation(route):
    # Mutating a solution by selecting a contiguous group of four locations and shuffling their orde
    index = random.randint(0, len(route) - 4)
    route[index: index + 4] = random.sample(route[index: index + 4], 4)
    return route
​
def swap_mutation(route):
    # Picking two random locations and exchange their position in the solution
    index1, index2 = random.sample(range(len(route)), 2)
    route[index1], route[index2] = route[index2], route[index1]
    return route
​
def ruin_and_recreate_mutation(stops):
    # Generating a completely new solution at random
    new_route = random.sample(stops, len(stops))
    return new_route
​
def hill_climber_optimization(stops, distances, mutation_operator):
    population_size = 100
    num_parents = 10
    num_generations = 500
    mutation_rate = 0.1
​
    # Generating initial population
    population = [random.sample(stops, len(stops)) for _ in range(population_size)]
​
    best_fitnesses = []
    best_solution = None
​
    for generation in range(num_generations):
        fitnesses = [calculate_fitness(chromosome, distances) for chromosome in population]
​
        # Selecting parents
        parents = sorted(population, key=lambda x: calculate_fitness(x, distances))[:num_parents]
​
        # Generating child
        child = mutation_operator(random.choice(parents))
​
        # Mutation
        if random.random() < mutation_rate:
            child = mutation_operator(child)
​
        # Replacing worst parent with the child
        population.remove(max(parents, key=lambda x: calculate_fitness(x, distances)))
        population.append(child)
​
        # Updating best solution
        best_solution = min(population, key=lambda x: calculate_fitness(x, distances))
​
        # Storing best fitness
        best_fitness = calculate_fitness(best_solution, distances)
        best_fitnesses.append(best_fitness)
​
    return best_solution, best_fitnesses
​
​
# Performing hill climber optimization with shuffle mutation
best_solution, best_fitnesses = hill_climber_optimization(stops, distances, shuffle_mutation)
​
# Printing the best solution and its fitness
print("Best Solution (Shuffle Mutation):", best_solution)
print("Fitness (Shuffle Mutation):", calculate_fitness(best_solution, distances))
​
# Performing hill climber optimization with swap mutation
best_solution, best_fitnesses = hill_climber_optimization(stops, distances, swap_mutation)
​
# Printing the best solution and its fitness
print("Best Solution (Swap Mutation):", best_solution)
print("Fitness (Swap Mutation):", calculate_fitness(best_solution, distances))
​
# Performing hill climber optimization with ruin-and-recreate mutation
best_solution, best_fitnesses = hill_climber_optimization(stops, distances, lambda route: ruin_and_recreate_mutation(stops))
​
# Printing the best solution and its fitness
print("Best Solution (Ruin-and-Recreate Mutation):", best_solution)
print("Fitness (Ruin-and-Recreate Mutation):", calculate_fitness(best_solution, distances))
Best Solution (Shuffle Mutation): [12, 7, 2, 10, 3, 4, 9, 8, 11, 5, 1, 6]
Fitness (Shuffle Mutation): 86.7894293780921
Best Solution (Swap Mutation): [10, 5, 4, 6, 1, 2, 12, 8, 3, 7, 9, 11]
Fitness (Swap Mutation): 108.18305392218107
Best Solution (Ruin-and-Recreate Mutation): [7, 6, 11, 3, 2, 4, 10, 1, 9, 12, 8, 5]
Fitness (Ruin-and-Recreate Mutation): 43.09261004235973
Task 2.3 – Visualisation of results
esses = np.zeros(num_iterations)

for _ in range(num_runs):
    best_solution, best_fitnesses = hill_climber_optimization(stops, distances, ruin_and_recreate_mutation)
    ruin_avg_fitnesses += np.array(best_fitnesses[:num_iterations]) / num_runs
    ruin_max_fitnesses = np.maximum(ruin_max_fitnesses, best_fitnesses[:num_iterations])
    ruin_min_fitnesses = np.minimum(ruin_min_fitnesses, best_fitnesses[:num_iterations])

# Plotting
iterations = range(num_iterations)

# Shuffling Mutation
plt.plot(iterations, shuffle_avg_fitnesses, label='Shuffle Mutation (Avg)')
plt.plot(iterations, shuffle_max_fitnesses, label='Shuffle Mutation (Max)')
plt.plot(iterations, shuffle_min_fitnesses, label='Shuffle Mutation (Min)')

# Swapping Mutation
plt.plot(iterations, swap_avg_fitnesses, label='Swap Mutation (Avg)')
plt.plot(iterations, swap_max_fitnesses, label='Swap Mutation (Max)')
plt.plot(iterations, swap_min_fitnesses, label='Swap Mutation (Min)')

# Ruin-and-Recreate Mutation
plt.plot(iterations, ruin_avg_fitnesses, label='Ruin-and-Recreate Mutation (Avg)')
plt.plot(iterations, ruin_max_fitnesses, label='Ruin-and-Recreate Mutation (Max)')
plt.plot(iterations, ruin_min_fitnesses, label='Ruin-and-Recreate Mutation (Min)')

plt.xlabel('Iteration')
plt.ylabel('Fitness')
plt.title('Hill Climber Optimization')
plt.legend()
plt.show()
num_runs = 30
num_iterations = 500
​
# Performing hill climber optimization with shuffle mutation
shuffle_avg_fitnesses = np.zeros(num_iterations)
shuffle_max_fitnesses = np.zeros(num_iterations)
shuffle_min_fitnesses = np.zeros(num_iterations)
​
for _ in range(num_runs):
    best_solution, best_fitnesses = hill_climber_optimization(stops, distances, shuffle_mutation)
    shuffle_avg_fitnesses += np.array(best_fitnesses[:num_iterations]) / num_runs
    shuffle_max_fitnesses = np.maximum(shuffle_max_fitnesses, best_fitnesses[:num_iterations])
    shuffle_min_fitnesses = np.minimum(shuffle_min_fitnesses, best_fitnesses[:num_iterations])
​
# Performing hill climber optimization with swap mutation
swap_avg_fitnesses = np.zeros(num_iterations)
swap_max_fitnesses = np.zeros(num_iterations)
swap_min_fitnesses = np.zeros(num_iterations)
​
for _ in range(num_runs):
    best_solution, best_fitnesses = hill_climber_optimization(stops, distances, swap_mutation)
    swap_avg_fitnesses += np.array(best_fitnesses[:num_iterations]) / num_runs
    swap_max_fitnesses = np.maximum(swap_max_fitnesses, best_fitnesses[:num_iterations])
    swap_min_fitnesses = np.minimum(swap_min_fitnesses, best_fitnesses[:num_iterations])
​
# Performing hill climber optimization with ruin-and-recreate mutation
ruin_avg_fitnesses = np.zeros(num_iterations)
ruin_max_fitnesses = np.zeros(num_iterations)
ruin_min_fitnesses = np.zeros(num_iterations)
​
for _ in range(num_runs):
    best_solution, best_fitnesses = hill_climber_optimization(stops, distances, ruin_and_recreate_mutation)
    ruin_avg_fitnesses += np.array(best_fitnesses[:num_iterations]) / num_runs
    ruin_max_fitnesses = np.maximum(ruin_max_fitnesses, best_fitnesses[:num_iterations])
    ruin_min_fitnesses = np.minimum(ruin_min_fitnesses, best_fitnesses[:num_iterations])
​
# Plotting
iterations = range(num_iterations)
​
# Shuffling Mutation
plt.plot(iterations, shuffle_avg_fitnesses, label='Shuffle Mutation (Avg)')
plt.plot(iterations, shuffle_max_fitnesses, label='Shuffle Mutation (Max)')
plt.plot(iterations, shuffle_min_fitnesses, label='Shuffle Mutation (Min)')
​
# Swapping Mutation
plt.plot(iterations, swap_avg_fitnesses, label='Swap Mutation (Avg)')
plt.plot(iterations, swap_max_fitnesses, label='Swap Mutation (Max)')
plt.plot(iterations, swap_min_fitnesses, label='Swap Mutation (Min)')
​
# Ruin-and-Recreate Mutation
plt.plot(iterations, ruin_avg_fitnesses, label='Ruin-and-Recreate Mutation (Avg)')
plt.plot(iterations, ruin_max_fitnesses, label='Ruin-and-Recreate Mutation (Max)')
plt.plot(iterations, ruin_min_fitnesses, label='Ruin-and-Recreate Mutation (Min)')
​
plt.xlabel('Iteration')
plt.ylabel('Fitness')
plt.title('Hill Climber Optimization')
plt.legend()
plt.show()
